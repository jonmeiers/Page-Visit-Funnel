{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "1652\n",
      "82.6\n",
      "35.0574712644\n",
      "36.2831858407\n",
      "0 days 00:42:33.333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "visits = pd.read_csv('visits.csv',\n",
    "                     parse_dates=[1])\n",
    "cart = pd.read_csv('cart.csv',\n",
    "                   parse_dates=[1])\n",
    "checkout = pd.read_csv('checkout.csv',\n",
    "                       parse_dates=[1])\n",
    "purchase = pd.read_csv('purchase.csv',\n",
    "                       parse_dates=[1])\n",
    "\n",
    "# 1. We inspect the dfs using print and head:\n",
    "\n",
    "#print(visits.head())\n",
    "#print(cart.head())\n",
    "#print(checkout.head())\n",
    "#print(purchase.head())\n",
    "\n",
    "# After inspecting the dfs, we verify that there are no duplicate user ids in the df visits. \n",
    "\n",
    "#print(len(visits)) # 2000\n",
    "#print(visits.user_id.nunique()) # 2000\n",
    "\n",
    "# Since there are 2000 unique users out of 2000 rows, we know that there are no duplicate \n",
    "# ids in the visits df. This is important since using len(visits) will match the number of \n",
    "# individual users in this funnel.\n",
    "\n",
    "# We verify duplicate user ids in the df cart.\n",
    "\n",
    "#print(len(cart)) # 400\n",
    "#print(cart.user_id.nunique()) # 348\n",
    "\n",
    "# This discrepancy shows that although there are 400 rows in the this df, \n",
    "# only 348 individual users are represented, indicating that there must be duplicate \n",
    "# users under the user_id column.\n",
    "\n",
    "# We verify duplicate user ids in the df checkout\n",
    "\n",
    "#print(len(checkout)) # 360\n",
    "#print(checkout.user_id.nunique()) # 226\n",
    "\n",
    "# We verify duplicate user ids in the df purchase\n",
    "\n",
    "#print(len(purchase)) # 252\n",
    "#print(purchase.user_id.nunique()) # 144\n",
    "\n",
    "# Since 3 out of 4 dfs contain duplicate user ids, we must construct new dfs that only account \n",
    "# for each individual user id, in order to have accurate analytics involving our funnel. \n",
    "# The df visits will not need to be re-constructed.\n",
    "\n",
    "cart.drop_duplicates(subset='user_id', keep='first', inplace=True)\n",
    "cart.reset_index(inplace=True, drop=True)\n",
    "#print(len(cart)) # the number is now 348\n",
    "\n",
    "checkout.drop_duplicates(subset='user_id', keep='first', inplace=True)\n",
    "checkout.reset_index(inplace=True, drop=True)\n",
    "#print(len(checkout)) # the number is now 226\n",
    "\n",
    "purchase.drop_duplicates(subset='user_id', keep='first', inplace=True)\n",
    "purchase.reset_index(inplace=True, drop=True)\n",
    "#print(len(purchase)) # the number is now 144\n",
    "\n",
    "# 2. We combine visits and cart using a left merge\n",
    "\n",
    "visits_cart = pd.merge(\n",
    "    visits,\n",
    "    cart,\n",
    "    how='left')\n",
    "#print(visits_cart)\n",
    "\n",
    "# 3. How long is our merged DataFrame?\n",
    "\n",
    "print(len(visits_cart))\n",
    "# [2000 rows x 3 columns]\n",
    "\n",
    "# 4. How many of the timestamps are null for the column cart_time?\n",
    "\n",
    "# My original code:\n",
    "\n",
    "visits_count = visits_cart.visit_time.count()\n",
    "cart_time_count = visits_cart.cart_time.count()\n",
    "cart_time_null_count = visits_count - cart_time_count\n",
    "#print(cart_time_null_count) # 1652\n",
    "\n",
    "# More elegant code suggested by CA:\n",
    "\n",
    "cart_time_null_count = visits_cart[visits_cart.cart_time.isnull()]\n",
    "#print(cart_time_null_count)\n",
    "print(len(cart_time_null_count))\n",
    "# [1652 rows x 3 columns]\n",
    "\n",
    "# 1652 timestamps are null for the column cart_time, \n",
    "# meaning that out of all the people who visited the page (2000), \n",
    "# 1652 of them did not add anything to a cart.\n",
    "\n",
    "# 5. What percent of users who visited Cool T-Shirts Inc. ended up not placing a t-shirt in their cart?\n",
    "\n",
    "percent_visits_not_cart = (float(len(cart_time_null_count)) / float(len(visits_cart))) * 100\n",
    "print(percent_visits_not_cart) # 82.6%\n",
    "\n",
    "# 6. We repeat the left merge for cart and checkout and count null values. \n",
    "# What percentage of users put items in their cart, but did not proceed to checkout?\n",
    "\n",
    "cart_checkout = pd.merge(\n",
    "    cart,\n",
    "    checkout,\n",
    "    how='left')\n",
    "#print(cart_checkout)\n",
    "\n",
    "checkout_time_null_count = cart_checkout[cart_checkout.checkout_time.isnull()]\n",
    "#print(checkout_time_null_count)\n",
    "#print(len(checkout_time_null_count)) # 122\n",
    "\n",
    "percent_cart_not_checkout = (float(len(checkout_time_null_count)) / float(len(cart_checkout))) * 100 \n",
    "print(percent_cart_not_checkout) # 35.06%\n",
    "\n",
    "# 7. We merge all four steps of the funnel, in order, using a series of left merges. \n",
    "# We save the results to the variable all_data. We examine the result using print and head.\n",
    "\n",
    "all_data = visits.merge(cart, how='left').merge(checkout, how='left').merge(purchase, how='left')\n",
    "#print(all_data.head())\n",
    "#print(len(all_data))\n",
    "\n",
    "# 8. What percentage of users proceeded to checkout, but did not purchase a t-shirt?\n",
    "\n",
    "checkout_purchase = pd.merge(\n",
    "    checkout, \n",
    "    purchase, \n",
    "    how='left')\n",
    "#print(checkout_purchase)\n",
    "#print(len(checkout_purchase)) # 226\n",
    "\n",
    "purchase_time_null_count = checkout_purchase[checkout_purchase.purchase_time.isnull()]\n",
    "#print(purchase_time_null_count)\n",
    "#print(len(purchase_time_null_count)) # 82\n",
    "\n",
    "percent_checkout_not_purchase = (float(len(purchase_time_null_count)) / float(len(checkout_purchase))) * 100\n",
    "print(percent_checkout_not_purchase) # 36.28%\n",
    "\n",
    "# 9. Which step of the funnel is weakest (i.e., has the highest percentage of users not completing it)? \n",
    "# How might Cool T-Shirts Inc. change their website to fix this problem?\n",
    "\n",
    "# percent_visits_not_cart = 82.6%\n",
    "# percent_cart_not_checkout = 35.06%\n",
    "# percent_checkout_not_purchase = 36.28%\n",
    "\n",
    "# The weakest step of the funnel is from users initially visiting \n",
    "# to actually placing an item in their cart.\n",
    "# Fixes: the \"add to cart\" button can be made more conspicuous by changing \n",
    "# it's color to stand out more; pre-highlighting the button so users see it \n",
    "# \"pre-selected\"; placing the \"add to cart\" button to a place where users are \n",
    "# more likely to look, such as the top of the page, if possible; perhaps \n",
    "# discounting prices on select items to incentivize visitors to buy more; \n",
    "# and using cookies or some type of tracking to offer visitors types of \n",
    "# T-shirts they are more likely to buy.\n",
    "\n",
    "# 10. Using the giant merged DataFrame all_data that we created, \n",
    "# let's calculate the average time from initial visit to final purchase.\n",
    "\n",
    "all_data['time_to_purchase'] = \\\n",
    "    all_data.purchase_time - \\\n",
    "    all_data.visit_time\n",
    "#print(all_data.head())\n",
    "\n",
    "# 11. We examine the results using:\n",
    "\n",
    "#print(all_data.time_to_purchase)\n",
    "\n",
    "# 12. We calculate the average time to purchase using the following code:\n",
    "\n",
    "print(all_data.time_to_purchase.mean())\n",
    "# 0 days 00:42:33.333333"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
